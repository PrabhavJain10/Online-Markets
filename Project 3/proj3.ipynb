{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Outcomes from No-regret Learning in Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up and Algorithm Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWAlg:\n",
    "    def __init__(self, epsilon, k, h, myBids, myValue):\n",
    "        self.weights = np.ones(k)\n",
    "        self.payoffs = np.zeros(k)\n",
    "        self.h = h\n",
    "        self.k = k\n",
    "        self.epsilon = epsilon\n",
    "        self.sumWeights = np.sum(self.weights)\n",
    "        self.probs = self.weights/self.sumWeights\n",
    "        self.myValue = myValue\n",
    "        self.myBids = myBids\n",
    "        self.myTotalValue = 0\n",
    "\n",
    "    def getBids(self):\n",
    "        return self.myBids\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.myValue\n",
    "\n",
    "    def getTotalValue(self):\n",
    "        return self.myTotalValue\n",
    "\n",
    "    def getAction(self):\n",
    "        j = np.random.choice(self.k, 1, p = self.probs)\n",
    "        return self.myBids[j.item()]\n",
    "    \n",
    "    def update(self, payoffs):\n",
    "        for j in range(len(payoffs)):\n",
    "            curPayoff = payoffs[j]\n",
    "            self.payoffs[j] = self.payoffs[j] + curPayoff\n",
    "            newWeight = (1+self.epsilon)**(self.payoffs[j]/self.h)\n",
    "            self.weights[j] = newWeight\n",
    "        self.sumWeights = np.sum(self.weights)\n",
    "        if(self.epsilon > 1):\n",
    "            self.weights = self.weights/self.sumWeights\n",
    "            self.sumWeights = np.sum(self.weights)\n",
    "        self.probs = self.weights/self.sumWeights\n",
    "        return\n",
    "\n",
    "    def generatePayoffs(self, winningBid, meWin):\n",
    "        if meWin:\n",
    "            self.myTotalValue += self.myValue - winningBid\n",
    "        payoffs = np.zeros(len(self.myBids))\n",
    "        for count, bid in enumerate(self.myBids):\n",
    "            if bid >= winningBid:\n",
    "                payoffs[count] = bid - self.myValue\n",
    "            else:\n",
    "                payoffs[count] = 0\n",
    "        return payoffs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.weights = np.ones(self.k)\n",
    "        self.payoffs = np.zeros(self.k)\n",
    "        self.sumWeights = np.sum(self.weights)\n",
    "        self.probs = self.weights/self.sumWeights\n",
    "        self.myTotalValue = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstPriceReserve:\n",
    "    # bidders have to be ordered the same way every time\n",
    "    # reserve given as a raw value\n",
    "    def __init__(self, numBidders, reserve = 0):\n",
    "        self.numBidders = numBidders\n",
    "        self.totalPayoffs = np.zeros(self.numBidders)\n",
    "        self.reserve = reserve\n",
    "        \n",
    "    def generate(self, bids):\n",
    "        winningBid = 0\n",
    "        winner = -1\n",
    "        tiedBidders = []\n",
    "        tied = False\n",
    "        # check bids of all bidders\n",
    "        for count, bid in enumerate(bids):\n",
    "            if bid > winningBid:\n",
    "                winningBid = bid\n",
    "                winner = count\n",
    "            elif (bid == winningBid) and (winner != -1):\n",
    "                tiedBidders.append(count)\n",
    "                tied = True\n",
    "        if tied : winner = random.choice(tiedBidders)\n",
    "        # see if winning bid is greater than reserve price\n",
    "        if (winningBid < self.reserve): \n",
    "            winningBid = self.reserve\n",
    "            winner = -1\n",
    "        return winningBid, winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPlayers = 2\n",
    "epsilons = [2,5]\n",
    "h = 1\n",
    "k = 20\n",
    "stepSize = 0.15\n",
    "\n",
    "def setUpPlayers() :\n",
    "    # set up our players\n",
    "    players = []\n",
    "    for count in range(numPlayers):\n",
    "    # pick a distribution and numPlayers values from it\n",
    "        playerValue = random.uniform(0,h)\n",
    "        # create possible bids using geometric discretization\n",
    "        playerBids = []\n",
    "        for j in range(k):\n",
    "            playerBids.append(playerValue - ((1 + stepSize)**(-j))*playerValue)\n",
    "        # create player\n",
    "        player = EWAlg(epsilons[count], k, h, playerBids, playerValue, )\n",
    "        players.append(player)\n",
    "    return players\n",
    "\n",
    "def conductAuction(players, auction, n = 100):\n",
    "    # do the action n times\n",
    "    allBids = []\n",
    "    allWinners = []\n",
    "    for i in range(n):\n",
    "        bids = []\n",
    "        # generate bids\n",
    "        for count, player in enumerate(players):\n",
    "            bids.append(player.getAction())\n",
    "        # conduct auction\n",
    "        winningBid, winner = auction.generate(bids)\n",
    "        # update payoffs\n",
    "        for count, player in enumerate(players):\n",
    "            if count == winner:\n",
    "                payoffs = player.generatePayoffs(winningBid, True)\n",
    "            else:\n",
    "                payoffs = player.generatePayoffs(winningBid, False)\n",
    "            player.update(payoffs)\n",
    "        allBids.append(bids)\n",
    "        allWinners.append(winner)\n",
    "    return allBids, allWinners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5038244486512475\n",
      "0.15\n",
      "[0.0, 0.06571623243277136, 0.12286078237431175, 0.17255169536695553, 0.21576118492577623, 0.2533346541073594, 0.28600723600438827, 0.31441817678441336, 0.33912334268008737, 0.3606060956328474, 0.3792867503743778, 0.39553079797570867, 0.4096560567594746, 0.4219388904844884, 0.43261961546276134, 0.44190720240039, 0.44998336495484964, 0.4570061150022059, 0.46311285417382003, 0.46842306214913665]\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "playerBids = []\n",
    "playerValue = random.uniform(0,1)\n",
    "stepSize = 0.15\n",
    "print(playerValue)\n",
    "print(stepSize)\n",
    "for j in range(k):\n",
    "    playerBids.append(playerValue - ((1 + stepSize)**(-j))*playerValue)\n",
    "print(playerBids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.648696632370703, 0.12361666759623624]\n",
      "[6.63197497 1.7953271 ]\n",
      "[[0.4197478  0.07915517]\n",
      " [0.41334311 0.0785462 ]\n",
      " [0.41583266 0.08038906]\n",
      " [0.40970105 0.0800967 ]\n",
      " [0.40799154 0.07938007]\n",
      " [0.39959302 0.08257138]\n",
      " [0.39784578 0.0773167 ]\n",
      " [0.40575558 0.08129788]\n",
      " [0.3967053  0.07910322]\n",
      " [0.39993841 0.08004943]\n",
      " [0.39230364 0.07903051]\n",
      " [0.40015593 0.07939445]\n",
      " [0.40579976 0.07872292]\n",
      " [0.39087983 0.08159831]\n",
      " [0.39763624 0.07696568]\n",
      " [0.38603773 0.0790308 ]\n",
      " [0.38250983 0.07788786]\n",
      " [0.38321423 0.07840694]\n",
      " [0.35354533 0.07580554]\n",
      " [0.3727526  0.07581354]\n",
      " [0.35056761 0.07484582]\n",
      " [0.36891068 0.0792439 ]\n",
      " [0.35795028 0.077139  ]\n",
      " [0.39251107 0.08053423]\n",
      " [0.3631634  0.07856163]\n",
      " [0.36700199 0.07911875]\n",
      " [0.33003148 0.07795509]\n",
      " [0.34997296 0.07792581]\n",
      " [0.35417069 0.07844693]\n",
      " [0.32797321 0.08009842]\n",
      " [0.32906845 0.07791665]\n",
      " [0.31373644 0.0773498 ]\n",
      " [0.34125043 0.08047029]\n",
      " [0.33248379 0.07828166]\n",
      " [0.31585858 0.07809854]\n",
      " [0.31991506 0.07884097]\n",
      " [0.30297792 0.07798124]\n",
      " [0.29951894 0.0784032 ]\n",
      " [0.29211812 0.07515506]\n",
      " [0.30732507 0.07774879]\n",
      " [0.28406623 0.07967496]\n",
      " [0.28316007 0.07955789]\n",
      " [0.28015601 0.07829836]\n",
      " [0.27863327 0.07911423]\n",
      " [0.25986167 0.07921439]\n",
      " [0.27224869 0.08023975]\n",
      " [0.25336055 0.08085711]\n",
      " [0.24501489 0.07782426]\n",
      " [0.2698293  0.0784483 ]\n",
      " [0.20787345 0.0775422 ]\n",
      " [0.22966245 0.07671898]\n",
      " [0.22602553 0.08013031]\n",
      " [0.22059719 0.07829235]\n",
      " [0.23240272 0.07922709]\n",
      " [0.23034057 0.0768972 ]\n",
      " [0.20772579 0.07886677]\n",
      " [0.19712553 0.07553492]\n",
      " [0.18499727 0.07710016]\n",
      " [0.21167017 0.07635068]\n",
      " [0.17727586 0.07917343]\n",
      " [0.18647784 0.07981164]\n",
      " [0.19460662 0.07573491]\n",
      " [0.18046153 0.08149738]\n",
      " [0.17633817 0.07874964]\n",
      " [0.21644115 0.07702416]\n",
      " [0.19287041 0.07769478]\n",
      " [0.18224728 0.07886777]\n",
      " [0.17490728 0.0789069 ]\n",
      " [0.16455969 0.07721468]\n",
      " [0.20070248 0.07982591]\n",
      " [0.15685279 0.07843138]\n",
      " [0.15861447 0.08062613]\n",
      " [0.16667597 0.08229597]\n",
      " [0.15701762 0.07914942]\n",
      " [0.16703746 0.07796617]\n",
      " [0.14427998 0.07810019]\n",
      " [0.15065019 0.07554969]\n",
      " [0.17144308 0.07848303]\n",
      " [0.18596482 0.07735893]\n",
      " [0.16657875 0.08062774]\n",
      " [0.14387028 0.08071187]\n",
      " [0.16969407 0.08149732]\n",
      " [0.14231427 0.07781182]\n",
      " [0.13725529 0.08203286]\n",
      " [0.15744532 0.08015491]\n",
      " [0.13662875 0.07796988]\n",
      " [0.12737924 0.0793069 ]\n",
      " [0.13911434 0.0796475 ]\n",
      " [0.13913034 0.07927361]\n",
      " [0.14980641 0.07855527]\n",
      " [0.14123094 0.08112303]\n",
      " [0.14308541 0.08187745]\n",
      " [0.13216689 0.07977751]\n",
      " [0.15626352 0.08053363]\n",
      " [0.1148341  0.08168956]\n",
      " [0.13597909 0.08102599]\n",
      " [0.1384308  0.08216796]\n",
      " [0.1502393  0.07865802]\n",
      " [0.12726415 0.07742544]\n",
      " [0.13592034 0.07940479]]\n"
     ]
    }
   ],
   "source": [
    "MCBound = 500\n",
    "n = 100\n",
    "reserveFrac = 0 #between 0 and 1\n",
    "reserveValue = reserveFrac * h\n",
    "# set up players\n",
    "players = setUpPlayers()\n",
    "# set up the auction \n",
    "auction = FirstPriceReserve(2, reserveValue)\n",
    "\n",
    "values = []\n",
    "totalWinnings = [[], []]\n",
    "possibleBids = []\n",
    "for player in players:\n",
    "    values.append(player.getValue())\n",
    "    possibleBids.append(player.getBids())\n",
    "\n",
    "MCBids = []\n",
    "MCWinners = []\n",
    "for i in range(MCBound):\n",
    "    # conduct auction\n",
    "    allBids, allWinners = conductAuction(players, auction, n)\n",
    "    for count, player in enumerate(players):\n",
    "        totalWinnings[count].append(player.getTotalValue())\n",
    "    # reset players -> they keep same learning rate and values\n",
    "    for player in players:\n",
    "        player.reset()\n",
    "    MCBids.append(allBids)\n",
    "    MCWinners.append(allWinners)\n",
    "avgBids = np.array(MCBids)\n",
    "avgBids = np.mean(avgBids, 0)\n",
    "totalWinnings = np.mean(np.array(totalWinnings), 1)\n",
    "\n",
    "print(values)\n",
    "print(totalWinnings)\n",
    "print(avgBids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MCBids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonteCarlo(numTrials, payoffGenerator, epsilon, k, h, n):\n",
    "    avgFinalPayoff = 0\n",
    "    avgRegretPerRound = [[] for i in range(numTrials)]\n",
    "    for trial in range(numTrials):\n",
    "        alg = EWAlg(epsilon, k, h)\n",
    "        finalPayoff = 0\n",
    "        actionPayoffs = np.zeros(k)\n",
    "        generator = payoffGenerator(k)\n",
    "        regretPerRound = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            payoffs = generator.generate()\n",
    "            j = alg.getAction()\n",
    "            myPayoff = payoffs[j]\n",
    "            actionPayoffs += payoffs\n",
    "            alg.update(payoffs)\n",
    "            finalPayoff += myPayoff\n",
    "            OPT = max(actionPayoffs)\n",
    "            regret = (OPT - finalPayoff).item() / (i+1)\n",
    "            regretPerRound[i] = regret\n",
    "        avgFinalPayoff += finalPayoff\n",
    "        avgRegretPerRound[trial] = regretPerRound\n",
    "    return avgFinalPayoff/numTrials, np.mean(avgRegretPerRound, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonteCarloTrackActions(numTrials, payoffGenerator, epsilon, k, h, n):\n",
    "    avgFinalPayoff = 0\n",
    "    avgRegretPerRound = [[] for i in range(numTrials)]\n",
    "    actionTrial = []\n",
    "    for trial in range(numTrials):\n",
    "        alg = EWAlg(epsilon, k, h)\n",
    "        finalPayoff = 0\n",
    "        actionPayoffs = np.zeros(k)\n",
    "        generator = payoffGenerator(k)\n",
    "        regretPerRound = np.zeros(n)\n",
    "        actions = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            payoffs = generator.generate()\n",
    "            j = alg.getAction()\n",
    "            actions[i] = j\n",
    "            myPayoff = payoffs[j]\n",
    "            actionPayoffs += payoffs\n",
    "            alg.update(payoffs)\n",
    "            finalPayoff += myPayoff\n",
    "            OPT = max(actionPayoffs)\n",
    "            regret = (OPT - finalPayoff).item() / (i+1)\n",
    "            regretPerRound[i] = regret\n",
    "        actionTrial.append(actions)\n",
    "        avgFinalPayoff += finalPayoff\n",
    "        avgRegretPerRound[trial] = regretPerRound\n",
    "    return avgFinalPayoff/numTrials, np.mean(avgRegretPerRound, axis=0), np.array(actionTrial)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Fair Payoffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each round i:\n",
    "\n",
    "Draw a payoff x ~ U[0,1] (i.e., from the uniform distribution on interval [0,1])\n",
    "\n",
    "Assign this payoff to the action j* that has the smallest total payoff so far, i.e., j* = argminj Vji-1 where Vji = Σir=1 vji. \n",
    "(All other actions get 0 payoff in round i.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99, -0.5, 0, 0.1, 0.1517, 0.2, 0.4, 0.7, 1, 2, 10, 1000]\n",
      "[12.572066468624602, 6.089115420080595, 4.952127590364313, 4.888985005026019, 4.662385648248368, 4.658095671678926, 4.491083295527148, 4.237502645046786, 3.988782430758382, 3.551178754492665, 2.1475778776821812, 0.3206374990307352]\n",
      "[-0.07164880805723829, -0.0066178097291542375, 0.0044772387027638095, 0.005445673155832275, 0.007507744684371933, 0.007499525986132154, 0.0091217183309684, 0.011695349045173858, 0.014306945820161048, 0.01850769358056152, 0.03260957846953832, 0.05091754046141372]\n"
     ]
    }
   ],
   "source": [
    "h = 1 # fixed\n",
    "# hyperparameters\n",
    "k = 10\n",
    "n = 100\n",
    "epsilons = [-0.99, -0.5, 0, 0.1, 0.1517, 0.2, 0.4, 0.7, 1, 2, 10, 1000] # to be studied\n",
    "monteCarloBound = 1000\n",
    "\n",
    "AFEpsilonPayoffs = []\n",
    "AFEpsilonRegretPerRound = []\n",
    "for epsilon in epsilons:\n",
    "    finalPayoff, regretPerRound = MonteCarlo(monteCarloBound, AdversarialFair, epsilon, k, h, n)\n",
    "    AFEpsilonPayoffs.append(finalPayoff)\n",
    "    AFEpsilonRegretPerRound.append(regretPerRound)\n",
    "\n",
    "AFEpsilonAvgRegrets = [i[99] for i in AFEpsilonRegretPerRound]\n",
    "print(epsilons)\n",
    "print(AFEpsilonPayoffs)\n",
    "print(AFEpsilonAvgRegrets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

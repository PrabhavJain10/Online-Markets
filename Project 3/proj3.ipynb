{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Outcomes from No-regret Learning in Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up and Algorithm Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWAlg:\n",
    "    def __init__(self, epsilon, k, h, myBids, myValue):\n",
    "        self.weights = np.ones(k)\n",
    "        self.payoffs = np.zeros(k)\n",
    "        self.h = h\n",
    "        self.k = k\n",
    "        self.epsilon = epsilon\n",
    "        self.sumWeights = np.sum(self.weights)\n",
    "        self.probs = self.weights/self.sumWeights\n",
    "        self.myValue = myValue\n",
    "        self.myBids = myBids\n",
    "        self.myTotalValue = 0\n",
    "\n",
    "    def getBids(self):\n",
    "        return self.myBids\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.myValue\n",
    "\n",
    "    def getTotalValue(self):\n",
    "        return self.myTotalValue\n",
    "\n",
    "    def getAction(self):\n",
    "        j = np.random.choice(self.k, 1, p = self.probs)\n",
    "        return j.item()\n",
    "    \n",
    "    def update(self, payoffs):\n",
    "        for j in range(len(payoffs)):\n",
    "            curPayoff = payoffs[j]\n",
    "            self.payoffs[j] = self.payoffs[j] + curPayoff\n",
    "            newWeight = (1+self.epsilon)**(self.payoffs[j]/self.h)\n",
    "            self.weights[j] = newWeight\n",
    "        self.sumWeights = np.sum(self.weights)\n",
    "        if(self.epsilon > 1):\n",
    "            self.weights = self.weights/self.sumWeights\n",
    "            self.sumWeights = np.sum(self.weights)\n",
    "        self.probs = self.weights/self.sumWeights\n",
    "        return\n",
    "\n",
    "    def generatePayoffs(self, winningBid, meWin):\n",
    "        if meWin:\n",
    "            self.myTotalValue += self.myValue - winningBid\n",
    "        payoffs = np.zeros(len(self.myBids))\n",
    "        for count, bid in enumerate(self.myBids):\n",
    "            if bid >= winningBid:\n",
    "                payoffs[count] = bid - self.myValue\n",
    "            else:\n",
    "                payoffs[count] = 0\n",
    "        return payoffs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.weights = np.ones(self.k)\n",
    "        self.payoffs = np.zeros(self.k)\n",
    "        self.sumWeights = np.sum(self.weights)\n",
    "        self.probs = self.weights/self.sumWeights\n",
    "        self.myTotalValue = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstPriceReserve:\n",
    "    # bidders have to be ordered the same way every time\n",
    "    # reserve given as a raw value\n",
    "    def __init__(self, numBidders, reserve = 0):\n",
    "        self.numBidders = numBidders\n",
    "        self.totalPayoffs = np.zeros(self.numBidders)\n",
    "        self.reserve = reserve\n",
    "        \n",
    "    def generate(self, bids):\n",
    "        winningBid = 0\n",
    "        winner = -1\n",
    "        tiedBidders = []\n",
    "        tied = False\n",
    "        # check bids of all bidders\n",
    "        for count, bid in enumerate(bids):\n",
    "            if bid > winningBid:\n",
    "                winningBid = bid\n",
    "                winner = count\n",
    "            elif (bid == winningBid) and (winner != -1):\n",
    "                tiedBidders.append(count)\n",
    "                tied = True\n",
    "        if tied : winner = random.choice(tiedBidders)\n",
    "        # see if winning bid is greater than reserve price\n",
    "        if (winningBid < self.reserve): \n",
    "            winningBid = self.reserve\n",
    "            winner = -1\n",
    "        return winningBid, winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPlayers = 2\n",
    "epsilons = [2,5]\n",
    "h = 5\n",
    "k = 100\n",
    "stepSize = 1/k * (np.log(h))\n",
    "reserveFrac = 0 #between 0 and 1\n",
    "reserveValue = reserveFrac * h\n",
    "\n",
    "def setUpPlayers() :\n",
    "    # set up our players\n",
    "    players = []\n",
    "    for count in range(numPlayers):\n",
    "    # pick a distribution and numPlayers values from it\n",
    "        playerValue = random.uniform(0,h)\n",
    "        # create possible bids using geometric discretization\n",
    "        playerBids = []\n",
    "        for j in range(k):\n",
    "            playerBids.append(playerValue - (1 + stepSize)**(j+1))\n",
    "        # create player\n",
    "        player = EWAlg(epsilons[count], k, h, playerBids, playerValue, )\n",
    "        players.append(player)\n",
    "    return players\n",
    "\n",
    "def conductAuction(players, auction, n = 100):\n",
    "    # do the action n times\n",
    "    allBids = []\n",
    "    allWinners = []\n",
    "    for i in range(n):\n",
    "        bids = []\n",
    "        # generate bids\n",
    "        for count, player in enumerate(players):\n",
    "            bids.append(player.getAction())\n",
    "        # conduct auction\n",
    "        winningBid, winner = auction.generate(bids)\n",
    "        # update payoffs\n",
    "        for count, player in enumerate(players):\n",
    "            if count == winner:\n",
    "                payoffs = player.generatePayoffs(winningBid, True)\n",
    "            else:\n",
    "                payoffs = player.generatePayoffs(winningBid, False)\n",
    "            player.update(payoffs)\n",
    "        allBids.append(bids)\n",
    "        allWinners.append(winner)\n",
    "    return allBids, allWinners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016094379124341\n",
      "1.2991357539802573\n",
      "[0.2830413748559162, 0.2666879666921771, 0.2500713605774756, 0.23318732050420432, 0.21603154228884325, 0.19859965247471112, 0.18088720721705642, 0.16288969115020602, 0.14460251623647946, 0.12602102059657794, 0.10714046732115068, 0.08795604326323136, 0.06846285781124184, 0.04865594164224696, 0.028530245455144154, 0.008080638683464647, -0.012698091812541668, -0.033811243074873376, -0.05526419739813071, -0.07706242370160354, -0.09921147892344284, -0.12171700943726815, -0.14458475249157754, -0.16782053767232097, -0.1914302883890151, -0.21542002338477473, -0.23979585827064875, -0.2645640070846482, -0.2897307838758685, -0.3153026043141043, -0.3412859873253724, -0.36768755675375697, -0.3945140430499996, -0.42177228498726804, -0.44946923140453765, -0.47761194297803344, -0.5062075940211801, -0.5352634743135225, -0.5647869909590812, -0.5947856702746175, -0.6252671597082875, -0.6562392297891775, -0.6877097761082152, -0.7196868213309615, -0.7521785172427988, -0.7851931468270339, -0.8187391263764476, -0.8528250076388273, -0.8874594799970306, -0.9226513726841381, -0.9584096570342553, -0.9947434487695392, -1.031662010324036, -1.0691747532049158, -1.1072912403917143, -1.1460211887741856, -1.1853744716293904, -1.2253611211386544, -1.2659913309450321, -1.307275458751936, -1.3492240289635815, -1.3918477353679373, -1.4351574438628492, -1.479164195226043, -1.523879207929707, -1.569313881000373, -1.6154797969248291, -1.6623887246027962, -1.7100526223471284, -1.7584836409323017, -1.8076941266919626, -1.857696624666333, -1.9085038818002664, -1.9601288501927814, -2.0125846903988878, -2.065884774784557, -2.120042690935689, -2.1750722451219406, -2.2309874658163107, -2.287802607271356, -2.3455321531529822, -2.404190820232703, -2.463793562139334, -2.52435557317106, -2.5858922921688636, -2.6484194064522857, -2.7119528558185353, -2.776508836605964, -2.842103805822928, -2.9087544853431204, -2.9764778661684046, -3.045291212760274, -3.115212067441007, -3.1862582548656704, -3.258447886566085, -3.3317993655679317, -3.4063313910821664, -3.4820629632719315, -3.5590133880962016, -3.6372022822313728]\n"
     ]
    }
   ],
   "source": [
    "stepSize = 1/k * (np.log(h))\n",
    "print(stepSize)\n",
    "playerBids = []\n",
    "playerValue = random.uniform(0,h)\n",
    "print(playerValue)\n",
    "for j in range(k):\n",
    "    playerBids.append(playerValue - (1 + stepSize)**(j + 1))\n",
    "print(playerBids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3199825126459085, -0.3199825126459085, -0.3199825126459085, -0.3199825126459085, -0.3199825126459085, -0.3199825126459085, -0.3199825126459085, -0.3199825126459085, -0.3199825126459085, -0.3199825126459085]\n",
      "[-0.3336099346955608, -0.3336099346955608, -0.3336099346955608, -0.3336099346955608, -0.3336099346955608, -0.3336099346955608, -0.3336099346955608, -0.3336099346955608, -0.3336099346955608, -0.3336099346955608]\n",
      "[0.6800174873540915, 0.6663900653044392]\n",
      "[-303.95907317 -283.67966693]\n"
     ]
    }
   ],
   "source": [
    "MCBound = 500\n",
    "n = 100\n",
    "# set up players\n",
    "players = setUpPlayers()\n",
    "# set up the auction \n",
    "auction = FirstPriceReserve(2, reserveValue)\n",
    "\n",
    "values = []\n",
    "totalWinnings = [[], []]\n",
    "for player in players:\n",
    "    values.append(player.getValue())\n",
    "\n",
    "MCBids = []\n",
    "MCWinners = []\n",
    "for i in range(1):\n",
    "    # conduct auction\n",
    "    allBids, allWinners = conductAuction(players, auction, n)\n",
    "    for count, player in enumerate(players):\n",
    "        totalWinnings[count].append(player.getTotalValue())\n",
    "    # reset players -> they keep same learning rate and values\n",
    "    for player in players:\n",
    "        player.reset()\n",
    "    MCBids.append(allBids)\n",
    "    MCWinners.append(allWinners)\n",
    "\n",
    "    \n",
    "avgBids = np.array(MCBids)\n",
    "avgBids = np.mean(avgBids, 0)\n",
    "totalWinnings = np.mean(np.array(totalWinnings), 1)\n",
    "\n",
    "print(values)\n",
    "print(totalWinnings)\n",
    "# print(avgBids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(values)\n",
    "print(totalWinnings)\n",
    "print(MCWinners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonteCarlo(numTrials, payoffGenerator, epsilon, k, h, n):\n",
    "    avgFinalPayoff = 0\n",
    "    avgRegretPerRound = [[] for i in range(numTrials)]\n",
    "    for trial in range(numTrials):\n",
    "        alg = EWAlg(epsilon, k, h)\n",
    "        finalPayoff = 0\n",
    "        actionPayoffs = np.zeros(k)\n",
    "        generator = payoffGenerator(k)\n",
    "        regretPerRound = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            payoffs = generator.generate()\n",
    "            j = alg.getAction()\n",
    "            myPayoff = payoffs[j]\n",
    "            actionPayoffs += payoffs\n",
    "            alg.update(payoffs)\n",
    "            finalPayoff += myPayoff\n",
    "            OPT = max(actionPayoffs)\n",
    "            regret = (OPT - finalPayoff).item() / (i+1)\n",
    "            regretPerRound[i] = regret\n",
    "        avgFinalPayoff += finalPayoff\n",
    "        avgRegretPerRound[trial] = regretPerRound\n",
    "    return avgFinalPayoff/numTrials, np.mean(avgRegretPerRound, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonteCarloTrackActions(numTrials, payoffGenerator, epsilon, k, h, n):\n",
    "    avgFinalPayoff = 0\n",
    "    avgRegretPerRound = [[] for i in range(numTrials)]\n",
    "    actionTrial = []\n",
    "    for trial in range(numTrials):\n",
    "        alg = EWAlg(epsilon, k, h)\n",
    "        finalPayoff = 0\n",
    "        actionPayoffs = np.zeros(k)\n",
    "        generator = payoffGenerator(k)\n",
    "        regretPerRound = np.zeros(n)\n",
    "        actions = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            payoffs = generator.generate()\n",
    "            j = alg.getAction()\n",
    "            actions[i] = j\n",
    "            myPayoff = payoffs[j]\n",
    "            actionPayoffs += payoffs\n",
    "            alg.update(payoffs)\n",
    "            finalPayoff += myPayoff\n",
    "            OPT = max(actionPayoffs)\n",
    "            regret = (OPT - finalPayoff).item() / (i+1)\n",
    "            regretPerRound[i] = regret\n",
    "        actionTrial.append(actions)\n",
    "        avgFinalPayoff += finalPayoff\n",
    "        avgRegretPerRound[trial] = regretPerRound\n",
    "    return avgFinalPayoff/numTrials, np.mean(avgRegretPerRound, axis=0), np.array(actionTrial)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Fair Payoffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each round i:\n",
    "\n",
    "Draw a payoff x ~ U[0,1] (i.e., from the uniform distribution on interval [0,1])\n",
    "\n",
    "Assign this payoff to the action j* that has the smallest total payoff so far, i.e., j* = argminj Vji-1 where Vji = Σir=1 vji. \n",
    "(All other actions get 0 payoff in round i.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
